---
title: "Ordinary Least Squares"
author: "J. Alexander Branham"
date: "Fall 2016"
header-includes: 
  - \usetheme[titleformat=smallcaps, progressbar=frametitle]{metropolis}
output: 
  beamer_presentation:
    fig_caption: yes
    fig_height: 3
    incremental: yes
    slide_level: 3
    latex_engine: xelatex
classoption: aspectratio=169
---

```{r, echo=FALSE}
library(ggplot2)
```

# Introduction to Ordinary Least Squares
### OLS
* Ordinary least squares regression (OLS) is probably the most
  widely-used model in political science 
* At its core, it's all about drawing a line through data
* This allows us to asses the effect of $x$ on $y$
* Dependent variable $y$ must be continuous 
    + OLS makes other assumptions you'll learn about in stats II

### 
```{r, echo = FALSE}
p <- ggplot(mpg, aes(displ, hwy)) +
  geom_point()
p
```

### How to decide on a line?
```{r}
p <- p +  geom_abline(slope = -4, intercept = 37)
p
```

### How to decide
```{r}
p <- p +  geom_abline(slope = 4, intercept = 10, linetype = "dashed")
p
```

### how to decide
```{r}
p +  geom_smooth(method = "lm", se = FALSE, color = "red")
```

### OLS in R

```{r}
lm(hwy ~ displ, data = mpg) 
```

### Interpretation of coefficients
* Intercept - predicted $y$ when $x=0$
* Slope - a one unit change in $x$ leads to a (slope) unit change in
  $y$, on average 


  
### Residuals
* Notice that our line doesn't fit our data perfectly - we always make
  some error with our prediction
* That's referred to as the *residual*
* If we refer to our predicted value as $\hat{y}$, then we can
  calculate the residual for each observation with $e_i = y_i - \hat{y}_i$

### Fitting the best line
* OLS determines the "best" line by minimizing the sum of squared
  residuals
* How to find this?
* One option: Plug in all the values for the slope & intercept and
  calculate the sum of squared residuals for these infinity
  combinations
* That's problematic... 

### Multiple variables
* What if as years pass, engine size increases *and* fuel efficiency
  increases?
* Then the relationship we just observed might be *spurious*

```{r}
lm(hwy ~ displ + year, data = mpg) 
```


# OLS in Matrix Form
## Notation
### Notation
* Let's pretend that we know the **true** model
    + $Y$ is $nx1$ column vector
    + $X$ is $nxk(+1)$ matrix 
    + $\beta$ is $kx1$ column vector
    + $E$ is $nx1$ column vector
* Therefore, we have:
\pause

$$
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{bmatrix}
= 
\begin{bmatrix}
1 & x_{11} & x_{12} & \ldots & x_{1k} \\
1 & x_{21} & x_{22} & \ldots & x_{2k} \\
1 & \vdots & \vdots & \ldots & \vdots \\
1 & x_{n1} & x_{n2} & \ldots & x_{nk}
\end{bmatrix}
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\vdots \\
\beta_k
\end{bmatrix}
+ 
\begin{bmatrix}
e_1 \\
e_2 \\
\vdots \\
e_n
\end{bmatrix}
$$

### Matrix form
$$
Y = X\beta + E
$$

## OLS Estimates
### OLS **minimizes the sum of squared residuals**
* How to do that in matrix form? 
* First, what is sum of squared residuals?
* The residuals:
$$E = Y - X \hat{\beta}$$
* Sum of squared residuals:
$$E'E$$
* (show why on board)
* Alternatively, 
$$
\begin{split}
E'E & = (Y - X \hat{\beta})'(Y - X \hat{\beta}) \\
 & = Y'Y - \hat{\beta} X' Y - Y' X \hat{\beta} + \hat{\beta}' X'X \hat{\beta} \\
 & = Y'Y - 2 \hat{\beta}' X' Y + \hat{\beta} X'X \hat{\beta}
\end{split}
$$

### To **minimize** the sum of squares, we take the derivative
* Remember: 
$$E'E= Y'Y - 2 \hat{\beta}' X' Y + \hat{\beta} X'X \hat{\beta}$$
* The first derivative with respect to $\hat{\beta}$
$$\dfrac{\partial E'E}{\partial \hat{\beta}} = -2 X'Y + 2X'X\hat{\beta} = 0 $$
* To check that this is a minimum, we check to make sure that the second derivative is positive
* The second derivative is $2X'X$, which is positive definite so long as $X$ is full rank

### Solve for the estimator
* Here ya go:
$$-2 X'Y + 2X'X\hat{\beta} = 0 $$
* Move things around and divide by two:
$$X'Y =  X'X \hat{\beta}$$
* Premultiply each side by $(X'X)^{-1}$
$$(X'X)^{-1}X'Y = (X'X)^{-1}(X'X)\hat{\beta}$$
* We know that $(X'X)^{-1}(X'X)=I$
$$(X'X)^{-1}X'Y = I\hat{\beta}$$
* And $I$ is (kinda) like multiplying by 1 so :
$$(X'X)^{-1}X'Y = \hat{\beta}$$

