---
title: " Probability"
author: "J. Alexander Branham"
date: "Fall 2016"
header-includes: 
  - \usetheme[titleformat=smallcaps, progressbar=frametitle]{metropolis} 
output: 
  beamer_presentation:
    fig_caption: yes
    latex_engine: xelatex
    incremental: yes
    slide_level: 3
classoption: aspectratio=169
---

```{r, include=FALSE}
library(ggplot2)
```


# What is probability?
### Probability
* Frequency with which an event occurs
* Typically:
$$
Pr(A) = P(A) = \pi(A) = \dfrac{\text{Number of ways an event can occur}}{\text{Total number of possible outcomes}}
$$
* There are other ways of thinking about probability, but we'll stick with this one

### Kolmogorov's Axioms 
* First: $Pr(E)\in\mathbb{R}, Pr(E)\geq 0 \qquad \forall E\in F$
    + where $F$ is the event space 
    + Probabilities must be non-negative
* Second: $Pr(\Omega) = 1$
    + Where $\Omega$ is the sample space 
    + Something has to happen
    + Probabilities sum/integrate to 1
* Third: $Pr\left(\bigcup_{i = 1}^\infty E_i\right) = \sum_{i=1}^\infty Pr(E_i)$
    + The probability of disjoint (mutually exclusive) sets is equal to their sums 

# Probability Distributions
# Discrete
## Discrete
### Discrete probabilities 
* What's the probability that we'll roll a 3 on one die roll:
$$
Pr(y=3) = \dfrac{1}{6}
$$

* If one roll of the die is an "experiment"
* We can think of a 3 as a "success"
* And $Y \sim Bernoulli \left(\frac{1}{6} \right)$
* Fair coins are $\sim Bernoulli(.5)$ for example
* More generally $Bernoulli(\pi )$
    + $\pi$ represents the probability of success

### Binomial distributions
* Before we ran the experiment just once
* What happens if we run it multiple times?
$$
Pr(y_1=3, y_2=3) = \dfrac{1}{6} * \dfrac{1}{6}
$$

* Now $Y \sim Binomial \left(2, \dfrac{1}{.6} \right)$
    + Generally, $Y \sim Binomial(n, p)$
    + n = number of trials, p = probability of success
* PMF:
$$
{n \choose k} p^k (1-p)^{n-k}
$$

### You try! 
1. What's the probability of getting dealt the ace of spades?
2. What's the probability of rolling six five's in a row?

### You try (answers)
1. $$\frac{1}{52}$$
2. $${6 \choose 6} \frac{1}{6}^6 \left(1 - \frac{1}{6}\right)^6-6 \approx 0.00002$$

# Continuous distributions
## Continuous distributions
### The basics
* What happens when our outcome is continous
* Much harder to think about... 
* There are infinity possible outcomes
* Makes the denominator of our fraction difficult to work with 
* What's the probability that you make 15,293.19/year? 
* Probability of the whole space must equal 1
* Even if all events equally likely, $\dfrac{1}{\infty} =0$ 
    + Kinda...
    
### Continuous distributions - Normal
```{r, fig.height=3}
ggplot(data.frame(x = c(-5, 5)), aes(x)) + 
  stat_function(fun = dnorm)
```

### Continuous distributions - Uniform 
```{r, fig.height=2.25, fig.width=3}
ggplot(data.frame(x = c(-2, 2)), aes(x)) + 
  stat_function(fun = dunif)
```

### Probabilies and continuous distributions
* $Pr(y=c) = 0$
* $Pr(0<y<.5)$
$$
= \int_{0}^{.5} f(y) dy
$$

* For uniform from previous slide, $Pr(0<y<.5) = 0.5$

## Cumulative probabilities
### CDF
* CDF = Cumulative Distribution Function
* $F_X(x) = Pr(X\leq x)$

### Discrete
* $Y \sim Binom(10, .5)$
* What's the probability that $y\leq5$ ?
* $$\sum_{i=1}^5 Pr(Y=y_i)$$

### $Pr(y\leq 5)$
$$
\begin{split}
{10 \choose 1} .5^1 (1-.5)^{10-1} + \\
{10 \choose 2} .5^2 (1-.5)^{10-2} + \\
{10 \choose 3} .5^3 (1-.5)^{10-3} + \\
{10 \choose 4} .5^4 (1-.5)^{10-4} + \\
{10 \choose 5} .5^5 (1-.5)^{10-5}
\end{split}
$$

### Continous 
* We can't sum probabilities for continuous distributions (remember the 0 problem)
* Solution: integration
* $F_Y(y) = \int_{-\infty}^{y} f(y) dy$

# Marginal probability
### Marginal probability
* The $Pr$ of an event occurring:
    + $Pr(A)$
* Unconditional probability
* Probability of drawing a red card from a standard deck:
$$Pr(red) = \dfrac{1}{2}$$

# Joint probability
### Joint probability
* The probability of both $A$ **and** $B$
    + $Pr(A, B)$
* This is the intersection  of the two sets
* $Pr(A \cap B)$
    + Probability of drawing a red card and a 4:
    + $Pr(red, 4) = \dfrac{2}{52} = \dfrac{1}{26}$

# Conditional probability
### Conditional probability
* The probability of some event happening **given** some other event having occurred
    + $Pr(A|B)$
* You've drawn a red card. What's the probability it's a four?
    + $Pr(4 | red) = \dfrac{2}{26} = \dfrac{1}{13}$

### How to convert marginal, joint, and conditional probabilities
$$
Pr(A|B) = \dfrac{Pr(A,B)}{Pr(B)}
$$

The conditional probability is equal to the joint probability over the probability of the condition 

# Bayes' Law (Theorem)
### Bayes Law 
$$
Pr(A|B) = \dfrac{Pr(B|A) Pr(A)}{Pr(B)} = \dfrac{Pr(B|A) Pr(A)}{Pr(B|A)Pr(A) + Pr(B|\neg A) Pr(\neg A)}
$$

## Bayes example 1
### Bayes Example
* Police set up roadblock to randomly screen for potentially drunk drivers
* Person stopped and fails breathalyzer test
    + Test gives positive 98 percent of the time when person is drunk
    + Also gives positive 5 percent of the time when the person is actually sober 
    + We think that 1 percent of people going through the checkpoint are drunk 
* What is the probability that the man was actually drunk? 

### DWI Example
* Since he's randomly stopped, we think there is a 1 percent change he's drunk 
    + $Pr(drunk) = 0.01$
* Test accuracy:
    + $Pr(positive | drunk) = 0.98$
    + $Pr(positive | \neg drunk) = 0.05$
* Want to know:
    + $Pr(drunk | positive) = \dfrac{Pr(drunk) Pr(positive | drunk)}{Pr(positive)}$
* Everything known, except $Pr(positive)$

### $Pr(positive)$
$$
\begin{split}
Pr(positive) & = Pr(positive|drunk)Pr(drunk) \\
 & +Pr(positive|\neg drunk)Pr(\neg drunk)\\
 & = .98(.01) + .05(.99) \\
 & \approx .0593
\end{split}
$$

### $Pr(drunk | positive)$
* $Pr(drunk | positive) = \dfrac{Pr(drunk) Pr(positive | drunk)}{Pr(positive)}$
* $Pr(drunk | positive) = \dfrac{0.01(.98)}{.0593}$
* $.165$
* So there is a 16.5 percent chance that the man is drunk given that he tested positive

## Bayes example 2
### Example, take two: Monty Hall
* *Let's Make a Deal* was a game show where contestants were asked to choose one of three doors (A, B, and C). Behind one is a car and behind the other two are goats 
* Once contestants chose a door, Monty would open one of the doors they *didn't* choose that had a goat behind it
* The contestant could then either stick with their original choice or switch to the unopened door 
* Does switching doors increase your probability of winning? 
    + YES! 
    + Nearly 10,000 people wrote in refusing to believe this (including 1,000 PhDs!)
    
### Bayes's solution to Monty Hall
* $Pr(A) = Pr(B) = Pr(C) = \dfrac{1}{3}$ (prior belief about where the car is)
* WLOG assume contestant picks door $A$
* WLOG assume Monty opens door $B$
* Then: $Pr(B_{Monty}|A) = \dfrac{1}{2}$ and $Pr(B_{Monty}|B=0)$ and $Pr(B_{Monty}|C) = 1$

\pause

$$Pr(B_{Monty}, A) = Pr(B_{Monty}|A)Pr(A) = \dfrac{1}{2}* \dfrac{1}{3} = \dfrac{1}{6}$$
$$Pr(B_{Monty}, B) = Pr(B_{Monty}|B)Pr(B) = 0* \dfrac{1}{3} = 0$$
$$Pr(B_{Monty}, C) = Pr(B_{Monty}|C)Pr(C) = 1* \dfrac{1}{3} = \dfrac{1}{3}$$

\pause

* Note that $Pr(B_{Monty})= Pr(B_{Monty}, A) + Pr(B_{Monty}, B) + Pr(B_{Monty}, C) = \dfrac{1}{6} + 0 + \dfrac{1}{3} = \dfrac{1}{2}$

### $Pr(A|B_{Monty})$ and $Pr(C|B_{Monty})$
* $Pr(A|B_{Monty}) = \dfrac{Pr(A)Pr(B_{Monty} |A)}{Pr(B_{Monty})} = \dfrac{ \dfrac{1}{3} * \dfrac{1}{2}}{\dfrac{1}{2}} = \dfrac{1}{3}$
* $Pr(C|B_{Monty}) = \dfrac{Pr(C)Pr(B_{Monty} |C)}{Pr(B_{Monty})} = \dfrac{ \dfrac{1}{3} * 1}{\dfrac{1}{2}} = \dfrac{2}{3}$
* So switch! 
